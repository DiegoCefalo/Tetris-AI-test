{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "304a92ef-d034-45b9-8632-1023e47f7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tetris_engine as tr\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=300)\n",
    "from IPython.display import clear_output\n",
    "import random as rnd\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from random import random, randint, sample, seed\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import copy\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# import os, sys\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd8ee3b-ca42-4cc1-a5cf-0acccde07e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = tr.GameState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b31a85-3103-43ac-9574-05554df96c70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Viet Nguyen <nhviet1009@gmail.com>\n",
    "\"\"\" \n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Linear(5, 128), nn.BatchNorm1d(128), nn.LeakyReLU(inplace=True))\n",
    "        self.conv2 = nn.Sequential(nn.Linear(128, 128),nn.BatchNorm1d(128), nn.LeakyReLU(inplace=True))\n",
    "        self.conv3 = nn.Sequential(nn.Linear(128, 128),nn.BatchNorm1d(128), nn.LeakyReLU(inplace=True))\n",
    "        self.conv4 = nn.Sequential(nn.Linear(128, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200bc0be-0dca-4446-afcb-d7d946a5b095",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer with ReLU and BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, input_prev, embed_dim):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_prev, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linearblock_1 = LinearBlock(embed_dim, embed_dim)\n",
    "        self.linearblock_2 = LinearBlock(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.linearblock_1(x)\n",
    "        x = self.linearblock_2(x)\n",
    "        x += inputs # skip-connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.one_hot = nn.functional.one_hot\n",
    "        self.Stack = nn.Sequential(\n",
    "            LinearBlock(6, 32),\n",
    "            LinearBlock(32, 128),\n",
    "            LinearBlock(128, 500),\n",
    "            ResidualBlock(500),\n",
    "            ResidualBlock(500),\n",
    "            ResidualBlock(500),\n",
    "            ResidualBlock(500),\n",
    "        )\n",
    "        self.Prediction = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        # x = self.one_hot(x, num_classes=6).to(torch.float).reshape(-1, 324)\n",
    "        x = self.Stack(x)\n",
    "        logits = self.Prediction(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dc1676-504d-4e9e-bab9-fc0007e474b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class opt():\n",
    "    batch_size = 512\n",
    "    lr = 3e-3\n",
    "    gamma = 0.92\n",
    "    initial_epsilon=1\n",
    "    final_epsilon=5e-3\n",
    "    num_decay_epochs=2000\n",
    "    num_epochs=40000\n",
    "    save_interval=5000\n",
    "    replay_memory_size=30000\n",
    "    target_step = 1\n",
    "    log_path=\"tensorboard/lr0.003\"\n",
    "    saved_path=\"trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5e8f9c-81ba-47e2-8c75-bd1e2c9ea818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer with ReLU and BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, input_prev, embed_dim):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_prev, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linearblock_1 = LinearBlock(embed_dim, embed_dim)\n",
    "        self.linearblock_2 = LinearBlock(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.linearblock_1(x)\n",
    "        x = self.linearblock_2(x)\n",
    "        x += inputs # skip-connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.one_hot = nn.functional.one_hot\n",
    "        self.Stack = nn.Sequential(\n",
    "            LinearBlock(207, 350),\n",
    "            LinearBlock(350, 500),\n",
    "            ResidualBlock(500),\n",
    "            ResidualBlock(500),\n",
    "            ResidualBlock(500)\n",
    "        )\n",
    "        self.Prediction = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        # x = self.one_hot(x, num_classes=6).to(torch.float).reshape(-1, 324)\n",
    "        x = self.Stack(x)\n",
    "        logits = self.Prediction(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf865ed4-dc36-4a6e-bfd6-7857298dd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt():\n",
    "    model = Model()\n",
    "    # model = DeepQNetwork()\n",
    "    # model = torch.load('trained_models/res_arq/tetris_res_arq_3000')\n",
    "    batch_size = 512\n",
    "    lr = 3e-4\n",
    "    gamma = 0.97\n",
    "    initial_epsilon=1\n",
    "    final_epsilon=5e-3\n",
    "    num_decay_epochs=1000\n",
    "    num_epochs=40000\n",
    "    save_interval=500\n",
    "    replay_memory_size=1000000\n",
    "    target_step = 20\n",
    "    render_every = 1\n",
    "    name = \"res_arq_allboard\"\n",
    "    log_path= f\"tensorboard/{name}\"\n",
    "    saved_path = f\"trained_models/{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c4c24e2-4d3c-41d8-88bd-e005bba4e53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed(3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "switch = False\n",
    "\n",
    "def train(opt):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(123)\n",
    "        \n",
    "    else:\n",
    "        torch.manual_seed(123)\n",
    "    if os.path.isdir(opt.log_path):\n",
    "        shutil.rmtree(opt.log_path)\n",
    "        \n",
    "    os.makedirs(opt.log_path)\n",
    "    \n",
    "    if not os.path.exists(f\"trained_models/{opt.name}\"):\n",
    "        os.makedirs(f\"trained_models/{opt.name}\")\n",
    "    \n",
    "    writer = SummaryWriter(opt.log_path)\n",
    "    \n",
    "    model = opt.model\n",
    "    target_model = copy.deepcopy(model)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    state = env.reinit()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        target_model.cuda()\n",
    "        state = state.cuda()\n",
    "\n",
    "    replay_memory = deque(maxlen=opt.replay_memory_size)\n",
    "    epoch = 0\n",
    "    tbscores=[]\n",
    "    tbcleared_lines=[]\n",
    "    \n",
    "    while epoch < opt.num_epochs:\n",
    "        # print('pepe')\n",
    "        next_steps = env.get_next_states()\n",
    "        # Exploration or exploitation\n",
    "        epsilon = opt.final_epsilon + (max(opt.num_decay_epochs - epoch, 0) * (\n",
    "                opt.initial_epsilon - opt.final_epsilon) / opt.num_decay_epochs)\n",
    "        u = random()\n",
    "        random_action = u <= epsilon\n",
    "        next_actions, next_states = zip(*next_steps.items())\n",
    "        next_states = torch.stack(next_states)\n",
    "        if torch.cuda.is_available():\n",
    "            next_states = next_states.cuda()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(next_states)[:, 0]\n",
    "        if random_action:\n",
    "            index = randint(0, len(next_steps) - 1)\n",
    "        else:\n",
    "            index = torch.argmax(predictions).item()\n",
    "        \n",
    "        next_state = next_states[index, :]\n",
    "        action = next_actions[index]\n",
    "        \n",
    "        reverse_x = env.fallingPiece['x']\n",
    "        reverse_rot = env.fallingPiece['rotation']\n",
    "        \n",
    "        env.fallingPiece['x'] = action[0]\n",
    "        env.fallingPiece['rotation'] = action[1]\n",
    "        if not env.isValidPosition():\n",
    "            env.fallingPiece['x'] = reverse_x\n",
    "            env.fallingPiece['rotation'] = reverse_rot\n",
    "            \n",
    "        final_score = env.score\n",
    "        final_cleared_lines = env.lines\n",
    "        \n",
    "        if epoch % opt.render_every == 0:\n",
    "            switch = True\n",
    "        \n",
    "        reward, done = env.frame_step([0,0,0,0,1,0], render=switch)[1:3]\n",
    "        \n",
    "        switch=False\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            next_state = next_state.cuda()\n",
    "        replay_memory.append([state, reward, next_state, done])\n",
    "        if done:\n",
    "            # final_score = env.score\n",
    "            # final_cleared_lines = env.lines\n",
    "            state = env.reinit() \n",
    "            if torch.cuda.is_available():\n",
    "                state = state.cuda()\n",
    "        else:\n",
    "            state = next_state\n",
    "            continue\n",
    "        \n",
    "        if len(replay_memory) < 2000:\n",
    "            continue\n",
    "        epoch += 1\n",
    "        # if epoch > 2300:\n",
    "        #     opt.batch_size += 1\n",
    "        batch = sample(replay_memory, min(len(replay_memory), opt.batch_size))\n",
    "        state_batch, reward_batch, next_state_batch, done_batch = zip(*batch)\n",
    "        # print(state_batch[16])\n",
    "        state_batch = torch.stack(tuple(state for state in state_batch))\n",
    "        reward_batch = torch.from_numpy(np.array(reward_batch, dtype=np.float32)[:, None])\n",
    "        next_state_batch = torch.stack(tuple(state for state in next_state_batch))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            state_batch = state_batch.cuda()\n",
    "            reward_batch = reward_batch.cuda()\n",
    "            next_state_batch = next_state_batch.cuda()\n",
    "            \n",
    "        q_values = model(state_batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_prediction_batch = target_model(next_state_batch)\n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "\n",
    "        y_batch = torch.cat(\n",
    "            tuple(reward if done else reward + opt.gamma * prediction for reward, done, prediction in\n",
    "                  zip(reward_batch, done_batch, next_prediction_batch)))[:, None]\n",
    "    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(q_values, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Train/Loss', loss.item()\n",
    "                          # np.array(tbscores[-50:]).mean()\n",
    "                          , epoch - 1)\n",
    "        \n",
    "        writer.add_scalar('Train/Score', final_score\n",
    "                          # np.array(tbscores[-50:]).mean()\n",
    "                          , epoch - 1)\n",
    "        writer.add_scalar('Train/Cleared lines', final_cleared_lines\n",
    "                          # np.array(tbcleared_lines[-50:]).mean()\n",
    "                          , epoch - 1)\n",
    "        \n",
    "        if epoch % opt.target_step == 0:\n",
    "            target_model.load_state_dict(model.state_dict())\n",
    "            # target_model = copy.deepcopy(model)\n",
    "    \n",
    "\n",
    "        print(\"Epoch: {}/{}, Action: {}, Score: {}, Cleared lines: {}\".format(\n",
    "            epoch,\n",
    "            opt.num_epochs,\n",
    "            action,\n",
    "            reward,\n",
    "            final_cleared_lines))\n",
    "        \n",
    "        # tbscores.append(final_score)\n",
    "        # tbcleared_lines.append(final_cleared_lines)\n",
    "        \n",
    "        \n",
    "\n",
    "        if epoch > 0 and epoch % opt.save_interval == 0:\n",
    "            torch.save(model, \"{}/tetris_{}_{}\".format(opt.saved_path, opt.name, epoch))\n",
    "\n",
    "    torch.save(model, \"{}/tetris_{}\".format(opt.saved_path, opt.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d1e2cd-b156-4282-9270-fd4075808ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2266/2657903232.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2266/1574830375.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \"\"\"\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \"\"\"\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061040b1-3f7a-4853-b879-b8051e1cdd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.frame_step([0,0,0,0,1,0])[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89286861-9759-410e-9adc-32105a8aa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ee8ea-e233-42a1-90b2-b4927a748b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a[-3:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b34f9b1-642a-4eec-8bb0-c2414b860b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([1] + env._board_to_num(env.board).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bb410bf-652e-4328-9104-350d23f0fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.get_next_states()[(-1,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39342725-092a-4be3-b037-ea511e2aa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 6\n",
    "count=0\n",
    "justonce=0\n",
    "for ind,x in enumerate(env.board[col][::-1]):\n",
    "    if x == '.':\n",
    "        try:\n",
    "            if env.board[col][::-1][ind+1] != '.' and justonce < 1:\n",
    "                justonce+=1\n",
    "                for y in env.board[col][::-1][ind:]:\n",
    "                    if y != '.':\n",
    "                        count+=1\n",
    "        except:\n",
    "            continue\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e9865-526e-499b-94f3-f53a1e4932d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S\n",
    "Z\n",
    "J\n",
    "L\n",
    "I\n",
    "O\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01a79299-ce09-4a19-b2eb-82c2edfc7690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.piecewidth(env.fallingPiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "420f4395-527e-4018-b05b-f0f2d32a5713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, False)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.reinit()\n",
    "# env.fallingPiece['x']=1\n",
    "# env.fallingPiece['y']=0\n",
    "# env.fallingPiece['rotation']=3\n",
    "# env.fallingPiece['shape']='L'\n",
    "# env.fallingPiece['color']=0\n",
    "env.frame_step([0,0,0,0,0,0])[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ae2a29-2bdf-4469-8991-925469c608ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape': 'T', 'rotation': 1, 'x': 3, 'y': 4, 'color': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.fallingPiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbd9ecb-64b7-49f1-9b65-ff24a991f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9cf7f-35f5-4660-ba8f-be465d20d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env._number_of_holes(env.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91517fd5-a3e0-4c48-b398-c03a2af22fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S_SHAPE_TEMPLATE = [['..OO.',\n",
    "                     '.OO..',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '..OO.',\n",
    "                     '...O.',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "Z_SHAPE_TEMPLATE = [['.OO..',\n",
    "                     '..OO.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '.OO..',\n",
    "                     '.O...',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "I_SHAPE_TEMPLATE = [['..O..',\n",
    "                     '..O..',\n",
    "                     '..O..',\n",
    "                     '..O..',\n",
    "                     '.....'],\n",
    "                    ['.....',\n",
    "                     'OOOO.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "O_SHAPE_TEMPLATE = [['.OO..',\n",
    "                     '.OO..',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "J_SHAPE_TEMPLATE = [['.O...',\n",
    "                     '.OOO.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..OO.',\n",
    "                     '..O..',\n",
    "                     '..O..',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['.OOO.',\n",
    "                     '...O.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '..O..',\n",
    "                     '.OO..',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "L_SHAPE_TEMPLATE = [['...O.',\n",
    "                     '.OOO.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '..O..',\n",
    "                     '..OO.',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['.OOO.',\n",
    "                     '.O...',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['.OO..',\n",
    "                     '..O..',\n",
    "                     '..O..',\n",
    "                     '.....',\n",
    "                     '.....']]\n",
    "\n",
    "T_SHAPE_TEMPLATE = [['..O..',\n",
    "                     '.OOO.',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '..OO.',\n",
    "                     '..O..',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['.OOO.',\n",
    "                     '..O..',\n",
    "                     '.....',\n",
    "                     '.....',\n",
    "                     '.....'],\n",
    "                    ['..O..',\n",
    "                     '.OO..',\n",
    "                     '..O..',\n",
    "                     '.....',\n",
    "                     '.....']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "360516d1-7560-4e94-a7c2-0a874b8f4dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece = J_SHAPE_TEMPLATE[3]\n",
    "minwidth=5\n",
    "maxwidth=0\n",
    "for x in piece:\n",
    "    if 'O' in x:\n",
    "        a = x.index('O')\n",
    "        b = max([i if x == \"O\" else 0 for i, x in enumerate(x)])\n",
    "        if a < minwidth:\n",
    "            minwidth = a\n",
    "        if b > maxwidth:\n",
    "            maxwidth = b\n",
    "maxwidth - minwidth + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "73e5dabb-1799-4676-9111-391c1bc7acbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2, -1, 0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(-2, 10 - env.piecewidth(L_SHAPE_TEMPLATE[1])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "15d0b6dc-f32a-4618-a055-ac20a9fc2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['1' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['1' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['1' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['1' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '1' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '1' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '1' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '1' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '1' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '1' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '1' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '1' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '1' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '1' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '1' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '1' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '1' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '1' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '1' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '1' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '1' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '1' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '1' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '1' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '1' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '1' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '1' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '1' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '1' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '1' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '1' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '1' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '1' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '1' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '1' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '1' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '1']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '1']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '1']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '1']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['1' '1' '1' '1' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '1' '1' '1' '1' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '1' '1' '1' '1' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '1' '1' '1' '1' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '1' '1' '1' '1' '.' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '1' '1' '1' '1' '.']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n",
      "[['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '.' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '0' '0' '.' '.' '.' '.' '.' '.']\n",
      " ['.' '.' '.' '0' '.' '.' '1' '1' '1' '1']\n",
      " ['0' '0' '0' '0' '.' '.' '0' '0' '0' '0']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(-2, 0): tensor([ 0.,  2., 16., 22.,  4.]),\n",
       " (-1, 0): tensor([ 0.,  2., 12., 22.,  4.]),\n",
       " (0, 0): tensor([ 0.,  2., 20., 22., 12.]),\n",
       " (1, 0): tensor([ 0.,  2., 20., 22.,  4.]),\n",
       " (2, 0): tensor([ 0.,  2., 12., 22.,  4.]),\n",
       " (3, 0): tensor([ 0.,  2., 18., 22.,  4.]),\n",
       " (4, 0): tensor([ 0.,  2., 20., 22.,  4.]),\n",
       " (5, 0): tensor([ 0.,  2., 20., 22.,  4.]),\n",
       " (6, 0): tensor([ 0.,  2., 20., 22.,  4.]),\n",
       " (7, 0): tensor([ 0.,  2., 16., 22.,  4.]),\n",
       " (0, 1): tensor([ 0., 12.,  8., 32.,  8.]),\n",
       " (1, 1): tensor([ 0., 13., 14., 33.,  8.]),\n",
       " (2, 1): tensor([ 0., 14., 12., 34.,  8.]),\n",
       " (3, 1): tensor([ 0., 19., 12., 39.,  7.]),\n",
       " (4, 1): tensor([ 0.,  4., 10., 24.,  6.]),\n",
       " (5, 1): tensor([ 0.,  3., 14., 23.,  5.]),\n",
       " (6, 1): tensor([ 0.,  2., 13., 22.,  4.])}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_next_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610d03e-87e7-4e70-ad9d-4fbde6f4f767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tetris",
   "language": "python",
   "name": "tetris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
